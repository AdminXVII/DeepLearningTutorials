.. _fcn_2D_segm:

Fully Convolutional Networks (FCN) for 2D segmentation
******************************************************

Summary
+++++++

Segmentation task is different from classification task because it require predicting
a class for each pixel of the input image, instead of only 1 class for the whole input.
Classification needs to understand *what* is in the input (namely, the context). However,
in order to predict what is in the input for each pixel, segmentation needs to recover
*what* is in the input, and *where*.

.. figure:: images/cat_segmentation.png
    :align: center
    :scale: 35%

    **Figure 1** : Segmentation network

TODO : reference de l'image

The **fully convolutional** network (FCN) owes its name to its architecture that
have only locally connected layers, such as convolution, pooling, upsampling and
no dense layer. It reduce the number of parameters and computation time. To obtain
its segmentation map (output), segmentation networks usually have 2 parts :

*  Convolution path : extract semantic/context information
*  Deconvolution path : recover spatial information

The **convolution path** is used to figure out and interpret the context, while the
**deconvolution path** is used to retrieve *where* in the image were detected the things
detected by the convolution path. Furthermore, to fully recover the spatial
information lost in the pooling or downsampling layers, we often use skip connections.

A skip connection is a connection that skips a least one layer. Here, it
is often used to transfer local information by concatenating or summing feature
maps from the convolution path
with feature maps from the deconvolution path. It helps combining context
information with spatial information.


Data
++++

Polyps



Model
+++++

The architecture for FCN network depends on the precision desired. The Figures
below show 3 different architectures : FCN32, FCN16 and FCN8. The convolutional
layers are represented as vertical lines between the pooling layers.
Those pooling layers explicitely show the relative size of the feature maps.

.. figure:: images/fcn.png
    :align: center
    :scale: 50%

    **Figure 2** : FCN architecture

**Difference between those 3 architectures**

These 3 different architectures differ in the stride for the last convolution,
and in the skip connections used to obtain their segmentation map, as you can
see in the image below. I will use the name *convolution path* for the network
up to *pool5*. Note that these 3 architectures have the same convolution path,
but their respective deconvolution path differ.


1. **FCN-32** : Directly produce the segmentation map from *pool5* by using a
deconvolution layer with stride 32.

2. **FCN-16** : Sum the 2x upsampled prediction from *pool5* with *pool4* to further
produce the segmentation map using a deconvolution layer with stride 16.

3. **FCN-8** : Sum the feature map obtained by summing *pool4* with the upsampled
*pool5* with *pool3*, and use a deconvolution with stride 8 on that feature map
to obtain the segmentation map.


.. figure:: images/fcn_schema.png
    :align: center
    :scale: 65%

    **Figure 3** : FCN architecture

As explained above, the deconvolution path is different, since it uses different
skip connection layers and different stride for the last convolution. It thus
yield different segmentation, as you can see in Figure 4 below. Combining layers
that have different precision helps retrieving fine and spatial information, as
well as coarse and context information.



.. figure:: images/fcn32_16_8.png
    :align: center
    :scale: 30%

    **Figure 4** : FCN results

Note that the FCN-8 architecture was used on the polyps dataset,
because it produces more precise segmentation map.


Metrics
=======

1. Per pixel accuracy

2. Jaccard (Intersection over Union)

More structured


Code - Citations - Contact
++++++++++++++++++++++++++

Code
====

The FCN8 implementation can be found in the following file:

* `fcn8.py <http://deeplearning.net/tutorial/code/fcn8.py>`_ : Defines the model.
* `train_fcn8.py <http://deeplearning.net/tutorial/code/train_fcn8.py>`_ : Training loop.


TODO : import model_helpers, dataset_loader, metrics



Papers
======

If you use this tutorial, please cite the following papers.

Fully Convolutional Networks for Semantic Segmentation

* `[pdf] <https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf>`__ reference

A Benchmark for Endoluminal Scene Segmentation of Colonoscopy Images

* `[pdf] <https://arxiv.org/pdf/1612.00799.pdf>`__ reference

Papers related to Theano:

* `[pdf] <http://www.iro.umontreal.ca/~lisa/pointeurs/nips2012_deep_workshop_theano_final.pdf>`__ Bastien, Frédéric, Lamblin, Pascal, Pascanu, Razvan, Bergstra, James, Goodfellow, Ian, Bergeron, Arnaud, Bouchard, Nicolas, and Bengio, Yoshua. Theano: new features and speed improvements. NIPS Workshop on Deep Learning and Unsupervised Feature Learning, 2012.

* `[pdf] <http://www.iro.umontreal.ca/~lisa/pointeurs/theano_scipy2010.pdf>`__ Bergstra, James, Breuleux, Olivier, Bastien, Frédéric, Lamblin, Pascal, Pascanu, Razvan, Desjardins, Guillaume, Turian, Joseph, Warde-Farley, David, and Bengio, Yoshua. Theano: a CPU and GPU math expression compiler. In Proceedings of the Python for Scientific Computing Conference (SciPy), June 2010.

Thank you!

Contact
=======

Please email

References
++++++++++

* ref1

* ref2
