.. _fcn_2D_segm:

Fully Convolutional Networks (FCN) for 2D segmentation
******************************************************

Summary
+++++++

Segmentation task is different from classification task because it requires predicting
a class for each pixel of the input image, instead of only 1 class for the whole input.
Classification needs to understand *what* is in the input (namely, the context). However,
in order to predict what is in the input for each pixel, segmentation needs to recover
not only *what* is in the input, but also *where*.

.. figure:: images/cat_segmentation.png
    :align: center
    :scale: 35%

    **Figure 1** : Segmentation network

TODO : reference de l'image

**Fully Convolutional Networks** (FCNs) owe their name to their architecture, which is
built only from locally connected layers, such as convolution, pooling and upsampling.
Note that no dense layer is used in this kind of architecture. This reduces the number
of parameters and computation time. To obtain a segmentation map (output), segmentation
networks usually have 2 parts :

*  Downsampling path : capture semantic/contextual information
*  Upsampling path : recover spatial information

The **downsampling path** is used to extract and interpret the context (*what*), while the
**upsampling path** is used to enable precise localization (*where*). Furthermore, to fully
recover the fine-grained spatial information lost in the pooling or downsampling layers, we
often use skip connections.

A skip connection is a connection that bypasses a least one layer. Here, it
is often used to transfer local information by concatenating or summing feature
maps from the downsampling path with feature maps from the upsampling path. Merging features
from various resolution levels helps combining context information with spatial information.


Data
++++

Polyps



Model
+++++

There are variants of the FCN architecture, which mainly differ in the spatial precision of
their output. For example, the figures below show the FCN-32, FCN-16 and FCN-8 variants. In the
figures, convolutional layers are represented as vertical lines between pooling layers, which
explicitely show the relative size of the feature maps.

.. figure:: images/fcn.png
    :align: center
    :scale: 50%

    **Figure 2** : FCN architecture

**Difference between the 3 FCN variants**

As shown below, these 3 different architectures differ in the stride of the last convolution,
and the skip connections used to obtain the output segmentation maps. We will use the term
*downsampling path* to refer to the network up to *pool5* layer and we will use the term
*upsampling path* to refer to the network composed of all layers after *pool5*. It is worth
noting that the 3 FCN architectures share the same downsampling path, but differ in their
respective upmsapling paths.


1. **FCN-32** : Directly produces the segmentation map from *pool5*, by using a
transposed convolution layer with stride 32.

2. **FCN-16** : Sums the 2x upsampled prediction from *pool5* with *pool4* and then
produces the segmentation map, by using a transposed convolution layer with stride 16.

3. **FCN-8** : Sums the 4x upsampled *pool5* with the 2x upsampled *pool4* and *pool3*,
and applies a transposed convolution layer with stride 8 on the resulting feature maps
to obtain the segmentation map.


.. figure:: images/fcn_schema.png
    :align: center
    :scale: 65%

    **Figure 3** : FCN architecture

As explained above, the upsampling paths of the FCN variants are different, since they
use different skip connection layers and strides for the last convolution, yielding
different segmentations, as shown in Figure 4. Combining layers that have different
precision helps retrieving fine-grained spatial information, as well as coarse
contextual information.

.. figure:: images/fcn32_16_8.png
    :align: center
    :scale: 30%

    **Figure 4** : FCN results

Note that the FCN-8 architecture was used on the polyps dataset below,
since it produces more precise segmentation map.


Metrics
=======

1. Per pixel accuracy

2. Jaccard (Intersection over Union)

More structured


Code - Citations - Contact
++++++++++++++++++++++++++

Code
====

The FCN-8 implementation can be found in the following file:

* `fcn8.py <http://deeplearning.net/tutorial/code/fcn8.py>`_ : Defines the model.
* `train_fcn8.py <http://deeplearning.net/tutorial/code/train_fcn8.py>`_ : Training loop.


TODO : import model_helpers, dataset_loader, metrics



Papers
======

If you use this tutorial, please cite the following papers.

Fully Convolutional Networks for Semantic Segmentation

* `[pdf] <https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf>`__ reference

A Benchmark for Endoluminal Scene Segmentation of Colonoscopy Images

* `[pdf] <https://arxiv.org/pdf/1612.00799.pdf>`__ reference

Papers related to Theano:

* `[pdf] <http://www.iro.umontreal.ca/~lisa/pointeurs/nips2012_deep_workshop_theano_final.pdf>`__ Bastien, Frédéric, Lamblin, Pascal, Pascanu, Razvan, Bergstra, James, Goodfellow, Ian, Bergeron, Arnaud, Bouchard, Nicolas, and Bengio, Yoshua. Theano: new features and speed improvements. NIPS Workshop on Deep Learning and Unsupervised Feature Learning, 2012.

* `[pdf] <http://www.iro.umontreal.ca/~lisa/pointeurs/theano_scipy2010.pdf>`__ Bergstra, James, Breuleux, Olivier, Bastien, Frédéric, Lamblin, Pascal, Pascanu, Razvan, Desjardins, Guillaume, Turian, Joseph, Warde-Farley, David, and Bengio, Yoshua. Theano: a CPU and GPU math expression compiler. In Proceedings of the Python for Scientific Computing Conference (SciPy), June 2010.

Thank you!

Contact
=======

Please email

References
++++++++++

* ref1

* ref2
